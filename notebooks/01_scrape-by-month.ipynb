{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitterscraper: Get full month\n",
    "> Author: [Dawn Graham](https://dawngraham.github.io/)\n",
    "\n",
    "Use twitterscraper to get historical tweets.\n",
    "\n",
    "Documentation:\n",
    "- https://pypi.org/project/twitterscraper/0.2.7/\n",
    "- https://github.com/taspinar/twitterscraper\n",
    "\n",
    "Notes:\n",
    "- To run this function, we can't get 'user location' with Tweepy due to Twitter limitations. If we want that info later, we could possibly do a separate function.\n",
    "- Query by location is only available for September 2010 or later.\n",
    "\n",
    "Versions used:\n",
    "- Python 3.6.6\n",
    "- pandas 0.23.4\n",
    "- tweepy 3.7.0\n",
    "- twitterscraper 0.9.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary and function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Tweepy API - needed to connect\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import API\n",
    "from tweepy import TweepError\n",
    "\n",
    "# For Twitterscraper\n",
    "from twitterscraper import query_tweets\n",
    "\n",
    "# For dataframes\n",
    "import datetime as dt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter Twitter API info the first time running this notebook, then delete.\n",
    "# Credentials will be saved into and loaded from separate pkl file.\n",
    "if not os.path.exists('secret_twitter_credentials.pkl'):\n",
    "    Twitter={}\n",
    "    Twitter['Consumer Key'] = ''\n",
    "    Twitter['Consumer Secret'] = ''\n",
    "    Twitter['Access Token'] = ''\n",
    "    Twitter['Access Token Secret'] = ''\n",
    "    with open('secret_twitter_credentials.pkl','wb') as f:\n",
    "        pickle.dump(Twitter, f)\n",
    "else:\n",
    "    Twitter=pickle.load(open('secret_twitter_credentials.pkl','rb'))\n",
    "\n",
    "auth = OAuthHandler(Twitter['Consumer Key'], Twitter['Consumer Secret'])\n",
    "auth.set_access_token(Twitter['Access Token'], Twitter['Access Token Secret'])\n",
    "\n",
    "api = API(auth)\n",
    "\n",
    "# If the authentication was successful, you should\n",
    "# see the name of the account print out\n",
    "print(api.me().name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create empty dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dictionary to collect tweets\n",
    "tweets_dict = {'timestamp':[],\n",
    "               'id':[],\n",
    "               'text':[],\n",
    "               'user':[],\n",
    "               'likes':[],\n",
    "               'replies':[],\n",
    "               'retweets':[],\n",
    "               'query':[]\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up `query_by_month()` function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_by_month(query, y, m, limit=None):\n",
    "    \n",
    "    # Get number of days in each the month\n",
    "    # Check for leap years\n",
    "    if (y%4==0 and y%100!=0 or y%400==0) & (m == 2):\n",
    "        total_d = 29\n",
    "    elif m == 2:\n",
    "        total_d = 28\n",
    "    elif m in [4, 6, 9, 11]:\n",
    "        total_d = 30\n",
    "    else:\n",
    "        total_d = 31\n",
    "    \n",
    "    # Set first start & end day\n",
    "    d = 1\n",
    "    end_d = d + 1\n",
    "    \n",
    "    # Run for number of days in month\n",
    "    for day in range(total_d):\n",
    "\n",
    "        # Set search begin date\n",
    "        begin = dt.date(y, m, d)\n",
    "\n",
    "        # Set search end date\n",
    "        # Enables setting to 1st day of next month to get results from last day of search month\n",
    "        if (end_d > total_d) & (m == 12):\n",
    "            end = dt.date(y+1, 1, 1)\n",
    "        elif end_d > total_d:\n",
    "            end = dt.date(y, m+1, 1)\n",
    "        else:\n",
    "            end = dt.date(y, m, end_d)\n",
    "\n",
    "        # Run twitterscraper query\n",
    "        for tweet in query_tweets(query, begindate=begin, enddate=end, limit=limit):\n",
    "            # Append info to tweets_dict\n",
    "            tweets_dict['timestamp'].append(tweet.timestamp)\n",
    "            tweets_dict['id'].append(tweet.id)\n",
    "            tweets_dict['text'].append(tweet.text)\n",
    "            tweets_dict['user'].append(tweet.user)\n",
    "            tweets_dict['likes'].append(tweet.likes)\n",
    "            tweets_dict['replies'].append(tweet.replies)\n",
    "            tweets_dict['retweets'].append(tweet.retweets)\n",
    "            tweets_dict['query'].append(query)\n",
    "\n",
    "        # Pause\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Increase begin and end search date by 1\n",
    "        d += 1\n",
    "        end_d += 1\n",
    "    \n",
    "    # Save to dataframe\n",
    "    tweets = pd.DataFrame(tweets_dict)\n",
    "    tweets.set_index('timestamp', inplace=True)\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query\n",
    "\n",
    "Notes:\n",
    "- Compile query here: https://twitter.com/search-advanced  \n",
    "- As long as you do not re-run cells above, new queries will continue to be added to dictionary.\n",
    "- After appending results to the csv, you can re-run above before starting new query to reduce duplicates in csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set search values and get results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter desired values for query\n",
    "query = 'poweroutage'\n",
    "year = 2012\n",
    "month = 10\n",
    "limit = 10\n",
    "\n",
    "# Run query\n",
    "tweets = query_by_month(query, year, month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check observations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of total vs unique observations\n",
    "print(f\"Total: {tweets.shape[0]}\")\n",
    "print(f\"Unique: {tweets['id'].nunique()}\")\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "tweets.drop_duplicates(inplace=True)\n",
    "print(f\"Total: {tweets.shape[0]}\")\n",
    "print(f\"Unique: {tweets['id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add results to csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append results to .csv file\n",
    "with open('../data/monthlytweets.csv', 'a') as f:\n",
    "    tweets.to_csv(f, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
